{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "실습_1_인공신경망기본.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Taeho-Kim-0322/Coding-Test/blob/master/%EC%8B%A4%EC%8A%B5_1_%EC%9D%B8%EA%B3%B5%EC%8B%A0%EA%B2%BD%EB%A7%9D%EA%B8%B0%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZ6F7TK29Y27"
      },
      "source": [
        "※ 기본 개념 정리\n",
        "1.   activation : 다음 층으로 어떻게 값을 넘길지 결정하는 부분. 가장 많이 사용되는 relu, sigmoid\n",
        "2.   loss : 한 번 신경망이 실행될 때마다 오차 값을 추적하는 함수\n",
        "3.   optimizer : 오차를 어떻게 줄여 나갈지 정하는 함수. e.g. SGD,...\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jeH-EOwoLse"
      },
      "source": [
        "TF 2.0 Tutorial(DL Camp) - MNIST 입니다.\n",
        "\n",
        "해당 문서는 TensorFlow 공식 Tutorial을 기반으로 수정하였습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiH7AC-NTniF"
      },
      "source": [
        "\n",
        "\n",
        "먼저 프로그램에 텐서플로 라이브러리를 임포트합니다:\n",
        "\n",
        "※ 자사 표준 라이브러리 TF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0trJmd6DjqBZ"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NAbSZiaoJ4z"
      },
      "source": [
        "데이터셋을 로드하여 준비합니다.\n",
        "\n",
        "공식적으로 제공하는 데이터셋은 [해당 링크](https://www.tensorflow.org/api_docs/python/tf/keras/datasets) 에서 확인할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqFRS6K07jJs"
      },
      "source": [
        "# data load\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data() \n",
        "\n",
        "# 0~255의 픽셀 값을 0~1로 조정\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# shape 조정\n",
        "x_train = x_train.reshape(60000,28,28,1)\n",
        "x_test = x_test.reshape(10000,28,28,1)\n",
        "\n",
        "# 정답 label을 길이10 벡터화\n",
        "y_train = tf.one_hot(y_train, depth=10)\n",
        "y_test = tf.one_hot(y_test, depth=10)\n",
        "\n",
        "# Training set으로부터 Validation set을 따로 분리.\n",
        "x_train, x_val = x_train[:50000], x_train[50000:]\n",
        "y_train, y_val = y_train[:50000], y_train[50000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9VmXaRappUz"
      },
      "source": [
        "Dataset의 shape와 실제 값은 아래와 같습니다. 이미지의 각각의 pixel 값이라고 생각하시면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEbcj2zrv5Jj"
      },
      "source": [
        "print(\"Train set input shape : \\t\", x_train.shape)\n",
        "print(\"Validation set input shape : \\t\", x_val.shape)\n",
        "print(\"Test set input shape : \\t\\t\", x_test.shape)\n",
        "print()\n",
        "print(\"Train set output shape : \\t\", y_train.shape)\n",
        "print(\"Validation set output shape : \\t\", y_val.shape)\n",
        "print(\"Test set output shape : \\t\", y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yz-pV-KF6_4Z"
      },
      "source": [
        "Train input : (5만건, 28 x 28, 흑백이미지)\n",
        "\n",
        "Validation input : (1만건, 28x28, 흑백이미지)\n",
        "\n",
        "Test input : (1만건, 28x28, 흑백이미지)\n",
        "\n",
        "\n",
        "Train output : (5만건, 길이 10의 열 벡터)\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ksNrVWJv-BC"
      },
      "source": [
        "해당하는 Dataset의 shape와 이미지는 아래와 같습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hma6sKm4potH"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "INDEX = 100\n",
        "\n",
        "plt.imshow(x_train[INDEX].reshape(28,28), cmap='gray_r')\n",
        "\n",
        "print(x_train[INDEX].shape) # 가로세로 28, 흑백\n",
        "print(y_train[INDEX]) # 정답 열벡터"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRrrqOxK7wsa"
      },
      "source": [
        "※ input은 동일한 shape로 넣어줘야 하므로, 실 생활 사례에서는 전처리가 필요하다\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPZ68wASog_I"
      },
      "source": [
        "인공신경망 아키텍처를 구성합니다. (교재상의 모델 구현)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3IKyzTCDNGo"
      },
      "source": [
        "model = Sequential([\n",
        "                    Flatten(), # 입력 데이터를 납작하게 1차원으로 눌러주는 역할\n",
        "                    Dense(15, activation='sigmoid'), # Dense : Layer 한 개 층을 더함, 뉴런의 갯수를 15개로 지정, 활성화함수를 sigmoid\n",
        "                    Dense(10, activation='softmax') # softmax는 가중합된 결과를 총 합이 1로 rescaling하여 가장 높은 값으로 분류한다.\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGih-c2LgbJu"
      },
      "source": [
        "훈련에 필요한 옵티마이저(optimizer)와 손실 함수를 선택합니다.\n",
        "\n",
        "현재는 MSE(Quadratic error) Loss 함수와 SGD Optimizer를 사용할 예정입니다.\n",
        "\n",
        "성능 평가는 분류정확도(accuracy)를 기준으로 합니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u48C9WQ774n4"
      },
      "source": [
        "# 학습의 환경설정\n",
        "my_opt = tf.keras.optimizers.SGD() # 경사하강법 Stochastic Gradient Descent\n",
        "my_loss = tf.keras.losses.MeanSquaredError() # 모델의 예측값 ↔ 실제값 비교 Loss함수 : MSE\n",
        "model.compile(optimizer=my_opt, loss=my_loss, metrics=['acc']) # accuracy 분류정확도"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8YT7UmFgpjV"
      },
      "source": [
        "이제 모델을 5 Epoch 동안 학습하면서, 테스트할 예정입니다.\n",
        "\n",
        "학습이 진행되는 동안 수집된 측정 지표를 바탕으로 최종 결과를 출력합니다.\n",
        "\n",
        "학습은 미니배치 32를 단위로 하여 진행합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OoMxpSKVT4x"
      },
      "source": [
        "EPOCHS = 5\n",
        "BATCH = 32\n",
        "history = model.fit(x=x_train, y=y_train, batch_size=BATCH, epochs=EPOCHS, validation_data=(x_val, y_val), verbose=1)\n",
        "# verbose = 실시간으로 로그를 찍어주는 방식을 설정함 1 ▶ 학습진행사항 다 찍어줌 0 ▶ 학습만 진행함"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTUydXeNoHhJ"
      },
      "source": [
        "test 데이터에 대해 최종 성능을 체크합니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFNcQL_foEtU"
      },
      "source": [
        "model.evaluate(x_test, y_test, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Vjnpwl31XVB"
      },
      "source": [
        "학습과정 동안의 Train Accuracy, Loss를 그래프로 확인할 수 있습니다. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_knfyrBoxsaO"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(5,5))\n",
        "plt.plot(range(1,EPOCHS+1), history.history['acc'], label=\"Train\")\n",
        "plt.plot(range(1,EPOCHS+1), history.history['val_acc'], label=\"Validation\")\n",
        "\n",
        "plt.title(\"Accuracy Graph\")\n",
        "plt.xticks(range(1,EPOCHS+1), range(1,EPOCHS+1))\n",
        "plt.legend(loc=2)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XTOo_0cWoHB"
      },
      "source": [
        "plt.figure(figsize=(5,5))\n",
        "plt.plot(range(1,EPOCHS+1), history.history['loss'], label=\"Train\")\n",
        "plt.plot(range(1,EPOCHS+1), history.history['val_loss'], label=\"Validation\")\n",
        "\n",
        "plt.title(\"Loss Graph\")\n",
        "plt.xticks(range(1,EPOCHS+1), range(1,EPOCHS+1))\n",
        "plt.legend(loc=3)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIuL-kvi1lVf"
      },
      "source": [
        "아래에는 Model의 구조와 Parameter 수를 확인할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_71WuwlUX5wN"
      },
      "source": [
        "model.summary()\n",
        "# Parameter : 최적화 하기 위해 찾아야 할 변수(가중치, 화살표)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYV88QcoI9Sn"
      },
      "source": [
        "# 실습 MISSION #1\n",
        "\n",
        "\n",
        "\n",
        "* 첫 번째 레이어 node 수 조정하기 : node 수 50 \n",
        "* 두 번째 레이어를 추가 : node 수 40\n",
        "* 세 번째 레이어를 추가 : node 수 30\n",
        "* 50 epoch동안 돌려보고 테스트 정확도를 확인해봅니다.\n",
        "* 하이퍼파라미터 조정하기 : Learning Rate 10.0 (개선의 정도 사람이 설정함)\n",
        "\n",
        "\n",
        "\n",
        "(힌트:learning rate은 파라미터를 업데이트할 때 이용됩니다. 어디에 넣어야 할까요?)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5DrwwFZ8W_c"
      },
      "source": [
        "model_1 = Sequential([\n",
        "                    Flatten(),\n",
        "                    Dense(50, activation='sigmoid'),\n",
        "                    Dense(40, activation='sigmoid'),\n",
        "                    Dense(30, activation='sigmoid'),\n",
        "                    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# 학습의 환경설정\n",
        "my_opt = tf.keras.optimizers.SGD(learning_rate=10.0)\n",
        "my_loss = tf.keras.losses.MeanSquaredError()\n",
        "model_1.compile(optimizer=my_opt, loss=my_loss, metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_EIwkthY0m2"
      },
      "source": [
        "EPOCHS = 50\n",
        "BATCH = 32\n",
        "history_1 = model_1.fit(x=x_train, y=y_train, batch_size=BATCH, epochs=EPOCHS, validation_data=(x_val, y_val), verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7D9I7gdY06O"
      },
      "source": [
        "model_1.evaluate(x_test, y_test, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QralkcLRbl6u"
      },
      "source": [
        "model_1.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1P1RblaTY0wN"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(5,5))\n",
        "plt.plot(range(1,EPOCHS+1), history_1.history['acc'], label=\"Train\")\n",
        "plt.plot(range(1,EPOCHS+1), history_1.history['val_acc'], label=\"Validation\")\n",
        "\n",
        "plt.title(\"Accuracy Graph\")\n",
        "plt.xticks(range(1,EPOCHS+1), range(1,EPOCHS+1))\n",
        "plt.legend(loc=2)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnax_SmpbmA-"
      },
      "source": [
        "plt.figure(figsize=(5,5))\n",
        "plt.plot(range(1,EPOCHS+1), history_1.history['loss'], label=\"Train\")\n",
        "plt.plot(range(1,EPOCHS+1), history_1.history['val_loss'], label=\"Validation\")\n",
        "\n",
        "plt.title(\"Loss Graph\")\n",
        "plt.xticks(range(1,EPOCHS+1), range(1,EPOCHS+1))\n",
        "plt.legend(loc=3)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBzAJldWnp10"
      },
      "source": [
        "# 실습 MISSION #2\n",
        "\n",
        "더 나은 성능을 내기 위해 네트워크를 수정해보자!\n",
        "\n",
        "아래 항목을 자유로이 변경하고 **test set**에 대한 성능을 확인해봅시다\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "* 레이어 수 \n",
        "* 레이어 당 노드 수\n",
        "* learning rate\n",
        "* epoch 수\n",
        "* mini-batch size\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjQ6bzEz8XQJ"
      },
      "source": [
        "model_2 = Sequential([\n",
        "                    Flatten(),\n",
        "                    Dense(10, activation='sigmoid'),\n",
        "                    Dense(10, activation='sigmoid'),\n",
        "                    Dense(10, activation='sigmoid'),\n",
        "                    Dense(10, activation='sigmoid'),\n",
        "                    Dense(10, activation='sigmoid'),\n",
        "                    Dense(10, activation='sigmoid'),\n",
        "                    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# 학습의 환경설정\n",
        "my_opt = tf.keras.optimizers.SGD(learning_rate=10.0) # 경사하강법 Stochastic Gradient Descent\n",
        "my_loss = tf.keras.losses.MeanSquaredError() # 모델의 예측값 ↔ 실제값 비교 Loss함수 : MSE\n",
        "model_2.compile(optimizer=my_opt, loss=my_loss, metrics=['acc']) # accuracy 분류정확도\n",
        "\n",
        "EPOCHS = 5\n",
        "BATCH = 32\n",
        "history_2 = model_2.fit(x=x_train, y=y_train, batch_size=BATCH, epochs=EPOCHS, validation_data=(x_val, y_val), verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tbu6QHzcPYR"
      },
      "source": [
        "model_2.evaluate(x_test, y_test, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlIW202XcPff"
      },
      "source": [
        "model_3 = Sequential([\n",
        "                    Flatten(),\n",
        "                    Dense(20, activation='sigmoid'),\n",
        "                    Dense(20, activation='sigmoid'),\n",
        "                    Dense(20, activation='sigmoid'),\n",
        "                    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# 학습의 환경설정\n",
        "my_opt = tf.keras.optimizers.SGD(learning_rate=10.0) # 경사하강법 Stochastic Gradient Descent\n",
        "my_loss = tf.keras.losses.MeanSquaredError() # 모델의 예측값 ↔ 실제값 비교 Loss함수 : MSE\n",
        "model_3.compile(optimizer=my_opt, loss=my_loss, metrics=['acc']) # accuracy 분류정확도\n",
        "\n",
        "EPOCHS = 5\n",
        "BATCH = 32\n",
        "history_3 = model_3.fit(x=x_train, y=y_train, batch_size=BATCH, epochs=EPOCHS, validation_data=(x_val, y_val), verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqsvHdYKcPOt"
      },
      "source": [
        "model_3.evaluate(x_test, y_test, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JP3KErehcs7A"
      },
      "source": [
        "model_4 = Sequential([\n",
        "                    Flatten(),\n",
        "                    Dense(30, activation='sigmoid'),\n",
        "                    Dense(30, activation='sigmoid'),\n",
        "                    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# 학습의 환경설정\n",
        "my_opt = tf.keras.optimizers.SGD(learning_rate=10.0) # 경사하강법 Stochastic Gradient Descent\n",
        "my_loss = tf.keras.losses.MeanSquaredError() # 모델의 예측값 ↔ 실제값 비교 Loss함수 : MSE\n",
        "model_4.compile(optimizer=my_opt, loss=my_loss, metrics=['acc']) # accuracy 분류정확도\n",
        "\n",
        "EPOCHS = 5\n",
        "BATCH = 32\n",
        "history_4 = model_4.fit(x=x_train, y=y_train, batch_size=BATCH, epochs=EPOCHS, validation_data=(x_val, y_val), verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PN4um7focsqb"
      },
      "source": [
        "model_4.evaluate(x_test, y_test, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-pQ6m6fc90D"
      },
      "source": [
        " model_5 = Sequential([\n",
        "                    Flatten(),\n",
        "                    Dense(30, activation='sigmoid'),\n",
        "                    Dense(30, activation='sigmoid'),\n",
        "                    Dense(10, activation='softmax')\n",
        "])\n",
        " \n",
        "# 학습의 환경설정\n",
        "my_opt = tf.keras.optimizers.SGD(learning_rate=10.0) # 경사하강법 Stochastic Gradient Descent\n",
        "my_loss = tf.keras.losses.MeanSquaredError() # 모델의 예측값 ↔ 실제값 비교 Loss함수 : MSE\n",
        "model_5.compile(optimizer=my_opt, loss=my_loss, metrics=['acc']) # accuracy 분류정확도\n",
        "\n",
        "EPOCHS = 20\n",
        "BATCH = 32\n",
        "history_5 = model_5.fit(x=x_train, y=y_train, batch_size=BATCH, epochs=EPOCHS, validation_data=(x_val, y_val), verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGEn-NL1fN7q"
      },
      "source": [
        "model_5.evaluate(x_test, y_test, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPXNCWI2ChWw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}